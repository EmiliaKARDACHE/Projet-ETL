# README DonnÃ©es â€” Traitement des donnÃ©es (brutes â†’ traitÃ©es)

## ğŸ¯ Objectif
DÃ©crire comment les donnÃ©es brutes sont ingÃ©rÃ©es, nettoyÃ©es, transformÃ©es et stockÃ©es sous forme dâ€™artÃ©facts prÃªts Ã  Ãªtre analysÃ©s ou consommÃ©s par des processus ETL.

## ğŸ“¦ Conventions sur les donnÃ©es clean
- Formats de fichiers csv
- Convention de nommage : `<source>_<sujet>.csv`
- Les fichiers bruts sont immuables. DÃ©placez les nouveaux fichiers dans `data/raw/` pour quâ€™ils soient ingÃ©rÃ©s par le pipeline.

## ğŸ”„ Ã‰tapes principales du pipeline

### 1. Parsing & normalisation
- Lecture du fichier CSV avec sÃ©parateur `;` depuis `data/raw/`.
- Normalisation des chaÃ®nes de caractÃ¨res : suppression des espaces en dÃ©but/fin de champ.
- Encodage supposÃ© en UTF-8.
- Les formats de date/heure ne sont pas prÃ©sents dans ce fichier, donc non modifiÃ©s.

### 2. Nettoyage
- Suppression de la colonne inutile `LCI Name` jugÃ©e inutile.
- Suppression des lignes contenant des valeurs manquantes (`dropna()`).
- Suppression des doublons exacts (`drop_duplicates()`).

### 3. Transformation / Enrichissement
- Aucune transformation mÃ©tier ou enrichissement par jointure nâ€™a Ã©tÃ© appliquÃ© Ã  ce stade.

### 4. Validation & QA
- Validation manuelle implicite via nettoyage et inspection.
- Aucun contrÃ´le de schÃ©ma formel ni rapport de validation gÃ©nÃ©rÃ© pour cette exÃ©cution.

### 5. Ã‰criture des artÃ©facts traitÃ©s
- Export du fichier nettoyÃ© au format CSV vers `data/processed/`.
- Pas de fichier de mÃ©tadonnÃ©es JSON gÃ©nÃ©rÃ© automatiquement pour cette Ã©tape, Ã  ajouter manuellement si nÃ©cessaire.
